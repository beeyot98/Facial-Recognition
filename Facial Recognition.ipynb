{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
    "from keras.optimizers import Adam,SGD, RMSprop \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = 48\n",
    "train_dir = \"Data/train\"\n",
    "test_dir = \"Data/test\"\n",
    "\n",
    "# Generate random transformation from Data to increase Dataset and prevent overfitting\n",
    "train_datagen = ImageDataGenerator( width_shift_range = 0.1,\n",
    "                                         height_shift_range = 0.1,\n",
    "                                         horizontal_flip = True,\n",
    "                                         rescale = 1./255,\n",
    "                                         zoom_range = 0.3,\n",
    "                                         validation_split = 0.2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory= train_dir,\n",
    "                                                    target_size = (img_size, img_size),\n",
    "                                                    shuffle = True,\n",
    "                                                    batch_size = 64,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\"\n",
    "                                                    )\n",
    "validation_generator = val_datagen.flow_from_directory (directory= test_dir,\n",
    "                                                        target_size = (img_size, img_size),\n",
    "                                                        shuffle = True,\n",
    "                                                        batch_size = 64,\n",
    "                                                        color_mode = \"grayscale\",\n",
    "                                                        class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building CNN Architecture\n",
    "    input_size = (48,48,1)\n",
    "    model = Sequential()   \n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = Adam(lr=0.0001, decay=1e-6), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1d19b86e370>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = 7\n",
    "get_model((48,48,1), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 22, 22, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 22, 22, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              31720448  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 32,116,743\n",
      "Trainable params: 32,116,103\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose model callback metrics\n",
    "import datetime\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "chk_path = 'ferNet.h5'\n",
    "log_dir = \"checkpoint/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=chk_path,\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             moniter='val_loss')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', \n",
    "                          min_delta=0, \n",
    "                          patience=3, \n",
    "                          verbose=1, \n",
    "                          restore_best_weights=True)\n",
    "                        \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.2, \n",
    "                              patience=6, \n",
    "                              verbose=1, \n",
    "                              min_delta=0.0001)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 4.3438 - accuracy: 0.2429\n",
      "Epoch 00001: val_loss improved from inf to 7.55287, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1766s 4s/step - loss: 4.3438 - accuracy: 0.2429 - val_loss: 7.5529 - val_accuracy: 0.1797\n",
      "Epoch 2/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 3.5652 - accuracy: 0.2859 \n",
      "Epoch 00002: val_loss improved from 7.55287 to 3.18680, saving model to ferNet.h5\n",
      "448/448 [==============================] - 5127s 11s/step - loss: 3.5652 - accuracy: 0.2859 - val_loss: 3.1868 - val_accuracy: 0.3597\n",
      "Epoch 3/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 3.0684 - accuracy: 0.3118\n",
      "Epoch 00003: val_loss improved from 3.18680 to 2.73105, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1610s 4s/step - loss: 3.0684 - accuracy: 0.3118 - val_loss: 2.7311 - val_accuracy: 0.3821\n",
      "Epoch 4/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 2.6670 - accuracy: 0.3307\n",
      "Epoch 00004: val_loss improved from 2.73105 to 2.33994, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1990s 4s/step - loss: 2.6670 - accuracy: 0.3307 - val_loss: 2.3399 - val_accuracy: 0.4089\n",
      "Epoch 5/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 2.3475 - accuracy: 0.3582\n",
      "Epoch 00005: val_loss improved from 2.33994 to 2.13197, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1557s 3s/step - loss: 2.3475 - accuracy: 0.3582 - val_loss: 2.1320 - val_accuracy: 0.4007\n",
      "Epoch 6/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 2.1067 - accuracy: 0.3826\n",
      "Epoch 00006: val_loss improved from 2.13197 to 1.96607, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1157s 3s/step - loss: 2.1067 - accuracy: 0.3826 - val_loss: 1.9661 - val_accuracy: 0.4195\n",
      "Epoch 7/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.9128 - accuracy: 0.4082\n",
      "Epoch 00007: val_loss improved from 1.96607 to 1.67549, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1136s 3s/step - loss: 1.9128 - accuracy: 0.4082 - val_loss: 1.6755 - val_accuracy: 0.4820\n",
      "Epoch 8/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.7584 - accuracy: 0.4329\n",
      "Epoch 00008: val_loss improved from 1.67549 to 1.62758, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1293s 3s/step - loss: 1.7584 - accuracy: 0.4329 - val_loss: 1.6276 - val_accuracy: 0.4703\n",
      "Epoch 9/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.6421 - accuracy: 0.4567\n",
      "Epoch 00009: val_loss improved from 1.62758 to 1.47113, saving model to ferNet.h5\n",
      "448/448 [==============================] - 1954s 4s/step - loss: 1.6421 - accuracy: 0.4567 - val_loss: 1.4711 - val_accuracy: 0.5124\n",
      "Epoch 10/60\n",
      "448/448 [==============================] - ETA: 0s - loss: 1.5472 - accuracy: 0.4819\n",
      "Epoch 00010: val_loss improved from 1.47113 to 1.39592, saving model to ferNet.h5\n",
      "448/448 [==============================] - 2372s 5s/step - loss: 1.5472 - accuracy: 0.4819 - val_loss: 1.3959 - val_accuracy: 0.5240\n",
      "Epoch 11/60\n",
      " 95/448 [=====>........................] - ETA: 20:28 - loss: 1.5092 - accuracy: 0.4850"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "steps_per_epoch = train_generator.n// batch_size\n",
    "validation_steps = validation_generator.n//batch_size\n",
    "\n",
    "history = model.fit(x=train_generator,\n",
    "                 validation_data=validation_generator,\n",
    "                 epochs=60,\n",
    "                 callbacks=callbacks,\n",
    "                 steps_per_epoch=steps_per_epoch,\n",
    "                 validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Model accuracy and loss\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model to file\n",
    "model.save_weights('model .h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
